{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasConvNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmxmAw/l/h1g9XHhRMGIwk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RihaChri/KerasConvNet/blob/main/KerasConvNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj0mI6L0NjX6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "import math\n",
        "import h5py\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def model(input_shape):\n",
        "    X_input = Input(input_shape)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
        "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
        "    return model\n",
        "\n",
        "# GRADED FUNCTION: HappyModel\n",
        "\n",
        "def HappyModel(input_shape):\n",
        "    \"\"\"\n",
        "    input_shape -- shape of the images of the dataset\n",
        "        (height, width, channels) as a tuple.  \n",
        "        Note that this does not include the 'batch' as a dimension.\n",
        "        If you have a batch like 'X_train', \n",
        "        then you can provide the input_shape using\n",
        "        X_train.shape[1:]\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    X_input = Input(input_shape)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
        "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
        "    return model\n",
        "\n",
        "def mean_pred(y_true, y_pred):\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "def load_dataset():\n",
        "    train_dataset = h5py.File('datasets/train_happy.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('datasets/test_happy.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "\n",
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig/255.\n",
        "X_test = X_test_orig/255.\n",
        "\n",
        "# Reshape\n",
        "Y_train = Y_train_orig.T\n",
        "Y_test = Y_test_orig.T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))\n",
        "\n",
        "\n",
        "\n",
        "happyModel = HappyModel((64,64,3))\n",
        "happyModel.compile(optimizer = \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
        "happyModel.fit(x = X_train,y = Y_train,epochs =40 ,batch_size = 16 )\n",
        "preds = happyModel.evaluate(x = X_test,y = Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))\n",
        "\n",
        "\n",
        "img_path = 'images/my_image.jpg'\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "imshow(img)\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "print(happyModel.predict(x))"
      ]
    }
  ]
}